{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 16:41:25.153602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 16:41:26.979619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/moritz/catkin_ws/devel/lib:/opt/ros/noetic/lib:/home/moritz/.mujoco/mujoco210/bin:/home/moritz/mambaforge/envs/contact/lib/:/home/moritz/mambaforge/envs/contact/lib/\n",
      "2023-02-18 16:41:26.980013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/moritz/catkin_ws/devel/lib:/opt/ros/noetic/lib:/home/moritz/.mujoco/mujoco210/bin:/home/moritz/mambaforge/envs/contact/lib/:/home/moritz/mambaforge/envs/contact/lib/\n",
      "2023-02-18 16:41:26.980026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/moritz/Documents/ContactGraspnetBenchmark/contact_graspnet/orig/pointnet2/tf_ops/sampling\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from contact_graspnet.orig.contact_graspnet import config_utils\n",
    "from contact_graspnet.orig.contact_graspnet.data import load_available_input_data\n",
    "from contact_graspnet.orig.contact_graspnet.contact_grasp_estimator import GraspEstimator\n",
    "from contact_graspnet.orig.contact_graspnet.visualization_utils import visualize_grasps, show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 16:41:33.254941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 16:41:33.277029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 16:41:33.277358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.disable_eager_execution()\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = Path.cwd().parent / \"contact_graspnet\" / \"checkpoints\" / \"scene_test_2048_bs3_hor_sigma_001\"\n",
    "input_path = Path.cwd().parent / \"contact_graspnet\" / \"data\" / \"test_data\" / \"7.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moritz/Documents/ContactGraspnetBenchmark/contact_graspnet/orig/contact_graspnet/config_utils.py:40: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  global_config = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "# this basically loads the config.yaml file in the checkpoint directory\n",
    "# we overwrite the batch_size with 1\n",
    "global_config = config_utils.load_config(checkpoint_dir, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Get model\n",
      "WARNING:tensorflow:From /home/moritz/mambaforge/envs/contact/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moritz/Documents/ContactGraspnetBenchmark/contact_graspnet/orig/pointnet2/utils/tf_util.py:571: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  momentum=bn_decay, axis=axis, name=scope,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/moritz/mambaforge/envs/contact/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:629: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /home/moritz/mambaforge/envs/contact/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pointclouds_pl': <tf.Tensor 'Placeholder:0' shape=(1, 20000, 3) dtype=float32>,\n",
       " 'cam_poses_pl': <tf.Tensor 'Placeholder_2:0' shape=(1, 4, 4) dtype=float32>,\n",
       " 'scene_idx_pl': <tf.Tensor 'Placeholder_1:0' shape=() dtype=int32>,\n",
       " 'is_training_pl': <tf.Tensor 'Placeholder_3:0' shape=() dtype=bool>,\n",
       " 'grasp_dir_pred': <tf.Tensor 'l2_normalize:0' shape=(1, 2048, 3) dtype=float32>,\n",
       " 'binary_seg_head': <tf.Tensor 'fc2_seg/BiasAdd:0' shape=(1, 2048, 1) dtype=float32>,\n",
       " 'binary_seg_pred': <tf.Tensor 'Sigmoid:0' shape=(1, 2048, 1) dtype=float32>,\n",
       " 'grasp_offset_head': <tf.Tensor 'fc2_off/BiasAdd:0' shape=(1, 2048, 10) dtype=float32>,\n",
       " 'grasp_offset_pred': <tf.Tensor 'Sigmoid_1:0' shape=(1, 2048, 10) dtype=float32>,\n",
       " 'approach_dir_pred': <tf.Tensor 'l2_normalize_1:0' shape=(1, 2048, 3) dtype=float32>,\n",
       " 'pred_points': <tf.Tensor 'layer1/GatherPoint:0' shape=(1, 2048, 3) dtype=float32>,\n",
       " 'offset_pred_idcs_pc': <tf.Tensor 'ArgMax_1:0' shape=(1, 2048) dtype=int64>,\n",
       " 'offset_bin_pred_vals': <tf.Tensor 'GatherNd:0' shape=(1, 2048) dtype=float32>,\n",
       " 'grasp_preds': <tf.Tensor 'concat_2:0' shape=(1, 2048, 4, 4) dtype=float32>,\n",
       " 'step': <tf.Variable 'Variable:0' shape=() dtype=int32>,\n",
       " 'end_points': {'grasp_dir_head': <tf.Tensor 'l2_normalize:0' shape=(1, 2048, 3) dtype=float32>,\n",
       "  'binary_seg_head': <tf.Tensor 'fc2_seg/BiasAdd:0' shape=(1, 2048, 1) dtype=float32>,\n",
       "  'binary_seg_pred': <tf.Tensor 'Sigmoid:0' shape=(1, 2048, 1) dtype=float32>,\n",
       "  'grasp_offset_head': <tf.Tensor 'fc2_off/BiasAdd:0' shape=(1, 2048, 10) dtype=float32>,\n",
       "  'grasp_offset_pred': <tf.Tensor 'Sigmoid_1:0' shape=(1, 2048, 10) dtype=float32>,\n",
       "  'approach_dir_head': <tf.Tensor 'l2_normalize_1:0' shape=(1, 2048, 3) dtype=float32>,\n",
       "  'pred_points': <tf.Tensor 'layer1/GatherPoint:0' shape=(1, 2048, 3) dtype=float32>}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model. In this implementation, the model is a wrapper around the \n",
    "# network itself and also contains preprocessing and postprocessing steps\n",
    "# and different utility methods\n",
    "grasp_estimator = GraspEstimator(global_config)\n",
    "grasp_estimator.build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 16:41:39.469943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 16:41:39.470611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 16:41:39.471136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 16:41:39.471595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 16:41:40.779767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 16:41:40.780345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 16:41:40.780884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 16:41:40.781185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1415 MB memory:  -> device: 0, name: NVIDIA GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(save_relative_paths=True)\n",
    "\n",
    "# Create a session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loading ', '/home/moritz/Documents/ContactGraspnetBenchmark/contact_graspnet/checkpoints/scene_test_2048_bs3_hor_sigma_001/model.ckpt-54054')\n",
      "INFO:tensorflow:Restoring parameters from /home/moritz/Documents/ContactGraspnetBenchmark/contact_graspnet/checkpoints/scene_test_2048_bs3_hor_sigma_001/model.ckpt-54054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 16:41:40.889316: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "grasp_estimator.load_weights(sess, saver, checkpoint_dir, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this tries to load the input data from the given path and accounts for different\n",
    "# keys which might be available in the input data\n",
    "# the example data only contains depth, rgb, segmentation and intrinsics data and no pointcloud\n",
    "# TODO rewrite this to use own data -> can we simply load the data without any conversions?\n",
    "segmap, rgb, depth, cam_K, _, _ = load_available_input_data(str(input_path))\n",
    "\n",
    "# segmap.shape  # (720,1280) 0 - 5\n",
    "# rgb.shape  # (720,1280,3) 0-255\n",
    "# depth.shape  # # (720,1280) 0 - 1\n",
    "# cam_K.shape  # (3,3)\n",
    "# pc_full # None\n",
    "# pc_colors # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in input_path.parent.iterdir():\n",
    "#     if not p.is_file() or p.suffix != \".npy\":\n",
    "#         continue\n",
    "\n",
    "#     print(np.load(p, allow_pickle=True).item().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model works on pointclouds, so we need to extract them from the depth image\n",
    "# TODO cehck if there is happening any special kind of conversion for which we might account in our data\n",
    "\n",
    "pc_full, pc_segments, pc_colors = grasp_estimator.extract_point_clouds(\n",
    "    depth,\n",
    "    cam_K,\n",
    "    segmap=segmap,\n",
    "    rgb=rgb,\n",
    "    skip_border_objects=False,\n",
    "    z_range=(0.2, 1.8),\n",
    ")\n",
    "\n",
    "# pc_full.shape # (510767, 3)\n",
    "# pc_colors.shape # (510767, 3)\n",
    "# pc_segments # Dict[float, np.ndarray]\n",
    "\n",
    "# for k,v in pc_segments.items():\n",
    "#     print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307200, 3)\n",
      "float64\n",
      "(510767, 3)\n",
      "float32\n",
      "Generated 157 grasps\n"
     ]
    }
   ],
   "source": [
    "from contact_graspnet.dataloading import YCBSimulationData\n",
    "ycb_data_path = Path.home() / \"Documents\" / \"ycb_sim_data_1\"\n",
    "ycb_sim_datset = YCBSimulationData(ycb_data_path)\n",
    "sample = ycb_sim_datset[0]\n",
    "pc_full_sim = sample.points\n",
    "\n",
    "print(pc_full_sim.shape)\n",
    "print(pc_full_sim.dtype)\n",
    "print(pc_full.shape)\n",
    "print(pc_full.dtype)\n",
    "\n",
    "pred_grasps_cam, scores, contact_pts, _ = grasp_estimator.predict_scene_grasps(\n",
    "    sess,\n",
    "    pc_full,\n",
    "    # pc_segments=pc_segments,\n",
    "    # local_regions=True,\n",
    "    # filter_grasps=False,\n",
    "    # forward_passes=1,\n",
    ")\n",
    "\n",
    "# pred_grasps_cam.keys() # (1, 100, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing...takes time\n"
     ]
    }
   ],
   "source": [
    "visualize_grasps(\n",
    "    pc_full, pred_grasps_cam, scores, plot_opencv_cam=True, pc_colors=pc_colors\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f37de04192e517ffd79099b0aa4f8a9ead4a2e1f477df475e17b2f61b1624210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
